% !TeX program = pdflatex
\documentclass[11pt,a4paper]{article}
\usepackage[margin=1in]{geometry}
\usepackage{graphicx}
\usepackage{booktabs}
\usepackage{multirow}
\usepackage{amsmath, amssymb}
\usepackage{tikz}
\usepackage{hyperref}
\usepackage{enumitem}
\usepackage{xcolor}
\hypersetup{colorlinks=true, linkcolor=blue, urlcolor=blue, citecolor=blue}

\title{Understanding Learning Dynamics in GAT+RL vs. GT+RL vs. DGT+RL for CVRP}
\author{Internal Technical Note}
\date{\today}

\begin{document}
\maketitle

\begin{abstract}
This document explains, in a novice-friendly way, why GAT+RL currently learns more convincingly than GT+RL and DGT+RL in our CVRP experiments (N=20), based on evidence from training CSV logs and the codebase. We describe architectural differences, how attention operates, where edge (distance) information enters, and why that matters for reinforcement learning stability. We also provide actionable recommendations and a short experimental plan to demonstrate the advantages of Transformer-based models (GT/DGT), especially at larger scales and dynamic settings. Tables and simple figures are included for clarity.
\end{abstract}

\section{Executive Summary}
\begin{itemize}[leftmargin=*]
  \item \textbf{Observed:} GAT+RL shows stronger learning and lower validation costs than GT+RL and DGT+RL on identical CVRP(20) distributions.
  \item \textbf{Root cause (high level):} GAT encodes \emph{edge} (distance) information directly into attention. GT/DGT encoders attend over \emph{node} features only; distances are used later (at the pointer/decoder), so the encoder's attention is less informed by the true routing costs. Combined with higher variance in REINFORCE, GT/DGT converge slower/weaker.
  \item \textbf{What to change now:} Add edge-aware attention biases/encodings to GT/DGT encoders; reduce RL variance via an actor--critic baseline; optionally warm-start with imitation.
  \item \textbf{Where GT/DGT can shine:} Larger instances (N=50/100) and dynamic variants (time, state updates) where Transformer capacity and DGT's dynamic state help.
\end{itemize}

\section{Learning Dynamics from CSVs}
We analyzed the repository CSVs under \texttt{results/smart\_search}. Mean training/validation costs and average train--validation gaps:\footnote{``Gap'' computed on aligned epochs: mean\,(train$-$validation).}

\begin{table}[h]
  \centering
  \caption{Learning dynamics summary (CVRP with 20 customers).}
  \label{tab:dynamics}
  \begin{tabular}{lrrrr}
    \toprule
    Model & Train Mean & Val Mean & Final Val (last) & Gap Mean \\
    \midrule
    GAT+RL & 0.6453 & 0.5126 & 0.4835 & 0.1392 \\
    DGT+RL & 0.6427 & 0.5717 & 0.5504 & 0.0792 \\
    GT+RL  & 0.6503 & 0.5818 & 0.5597 & 0.0714 \\
    \bottomrule
  \end{tabular}
\end{table}

\noindent Key takeaways:
\begin{itemize}[leftmargin=*]
  \item All models show \emph{validation} lower than \emph{training}. This is expected: training uses \emph{sampling} (exploration), validation uses \emph{greedy} decoding (exploitation).
  \item GAT+RL improves the most and validates best (lowest costs). DGT+RL improves, but less; GT+RL is the weakest among the three in this setup.
\end{itemize}

\section{Primer: How Attention Works Here}
\subsection{Nodes, edges, and attention}
In routing problems like CVRP, the "graph" has \textbf{nodes} (depot and customers) and \textbf{edges} whose weights are the Euclidean distances between nodes.

\paragraph{Self-attention in encoders.} For a set of node embeddings $x_i \in \mathbb{R}^d$, standard self-attention computes, for each node $i$, a weighted sum of all nodes $j$:
\[
\text{Attn}(i) \,=\, \sum_{j} \underbrace{\alpha_{ij}}_{\text{attention weight}} \, \underbrace{V x_j}_{\text{value proj.}},\quad \alpha_{ij} \propto \exp\!\left(\frac{(Qx_i)\,(Kx_j)^\top}{\sqrt{d}} + \underbrace{b_{ij}}_{\text{optional bias}}\right),
\]
where $Q,K,V$ are learned projections. The optional bias $b_{ij}$ can inject \emph{edge information} (e.g., a learned function of distance). If $b_{ij}=0$, attention depends only on node features.

\subsection{Where models differ}
\begin{itemize}[leftmargin=*]
  \item \textbf{GAT+RL (edge-aware):} The encoder uses edge (distance) features inside attention, shaping $\alpha_{ij}$ using geometry. This is akin to a Graph Attention Network (GAT), where messages are modulated by edge attributes.
  \item \textbf{GT+RL (vanilla Transformer encoder):} The encoder attends over \emph{node} features only; distances do not bias $\alpha_{ij}$ in the encoder. Distances are used later (e.g., in the pointer head) but not to form the encoder's contextual embeddings.
  \item \textbf{DGT+RL (dynamic Transformer):} Same as GT in the encoder (node-only attention), plus a dynamic state update (capacity used, progress, etc.) applied \emph{after} the encoder. Distances are again not used to bias encoder attention.
\end{itemize}

\paragraph{Clarification of the highlighted sentence.}
\emph{“GT+RL and DGT+RL transformer stacks embed only node features in the encoder layers. Distances are only injected downstream (pointer context or route features) but not shaping attention weights in the encoder itself.”}

This \textbf{does not} mean there is no attention over nodes. There \textbf{is} standard multi-head self-attention over nodes, but the \textbf{attention weights} $\alpha_{ij}$ are computed from node embeddings alone, without an edge-aware bias $b_{ij}$ derived from distances. In GAT+RL, the encoder attention effectively has a $b_{ij}$ term that reflects how far nodes are---a strong inductive bias for routing.

\subsection*{Why edge-aware attention helps}
Routing cost depends on \textbf{edges} (distances). If encoder attention "sees" distances, it can produce node embeddings already tuned to the geometry of the instance, easing the decoder's job and stabilizing RL. Without edge-aware biases, the encoder must infer geometry indirectly, which is harder and slower under REINFORCE.

\section{Illustrative Figures}
\subsection{Encoder attention: with vs. without edge bias}
\begin{figure}[h]
  \centering
  \begin{tikzpicture}[>=stealth, node distance=1.8cm]
    % Nodes
    \node[draw, rounded corners, fill=blue!8] (xi) {Query node $x_i$};
    \node[draw, rounded corners, fill=blue!8, right=3.6cm of xi] (xj) {All nodes $\{x_j\}$};

    % Without edge bias box
    \node[draw, rounded corners, below=1.0cm of xi, minimum width=7.5cm, align=left, fill=gray!8] (noedge) {
      \textbf{Vanilla encoder attention (GT/DGT):}\\
      $\alpha_{ij} \propto \exp\!\big( (Qx_i)(Kx_j)^\top/\sqrt{d}\big)$\\
      \small Edge distances are \emph{not} used to bias attention.
    };

    % With edge bias box
    \node[draw, rounded corners, above=1.0cm of xi, minimum width=7.5cm, align=left, fill=green!8] (edge) {
      \textbf{Edge-aware encoder attention (GAT-like):}\\
      $\alpha_{ij} \propto \exp\!\big( (Qx_i)(Kx_j)^\top/\sqrt{d} + b_{ij}(\text{dist}_{ij}) \big)$\\
      \small Distances shape attention weights; geometry informs context.
    };

    % Arrows
    \draw[->] (xi) -- node[above] {compute $\alpha_{ij}$} (xj);
    \draw[->] (edge) -- ++(6,0) node[right] {\small better geometry-aware embeddings};
    \draw[->] (noedge) -- ++(6,0) node[right] {\small geometry deferred to decoder};
  \end{tikzpicture}
  \caption{Encoder attention with (top) and without (bottom) distance-aware bias.}
  \label{fig:edgebias}
\end{figure}

\subsection{Where distances enter the pipeline}
\begin{figure}[h]
  \centering
  \begin{tikzpicture}[node distance=1.6cm, >=latex]
    \node[draw, rounded corners, fill=blue!8] (input) {Node coords \\ + demands};
    \node[draw, rounded corners, right=2.5cm of input, fill=yellow!10] (enc) {Encoder (self-attention)};
    \node[draw, rounded corners, right=2.5cm of enc, fill=orange!15] (ptr) {Pointer / Decoder};
    \node[draw, rounded corners, right=2.5cm of ptr, fill=red!10] (route) {Route};

    \draw[->] (input) -- (enc);
    \draw[->] (enc) -- (ptr);
    \draw[->] (ptr) -- (route);

    % Distance arrows
    \draw[->, thick, color=gray!70] ([yshift=8pt]input.east) -- node[above, sloped] {\small distances used} ([yshift=8pt]ptr.west);
    \node[above=0.45cm of enc] (ga) {\small \textbf{GT/DGT:} distances injected here $\Rightarrow$ decoder only};

    \draw[->, thick, color=green!60!black] ([yshift=-8pt]input.east) -- node[below, sloped] {\small distances used} ([yshift=-8pt]enc.west);
    \node[below=0.45cm of enc] (gb) {\small \textbf{GAT:} distances already shape encoder attention};
  \end{tikzpicture}
  \caption{In GT/DGT, distances affect mostly the decoder; in GAT they also shape encoder attention.}
  \label{fig:pipeline}
\end{figure}

\section{Why GAT+RL Learns Better at N=20}
\begin{enumerate}[leftmargin=*]
  \item \textbf{Right inductive bias for routing:} Edge-aware attention lets the encoder produce geometry-informed embeddings, simplifying the decoder's job.
  \item \textbf{Lower RL variance in practice:} With better encoder representations, REINFORCE gradients carry a cleaner signal. Transformers (GT/DGT) have higher capacity but, without edge cues, face noisier credit assignment.
  \item \textbf{DGT dynamic updates help when dynamics matter:} For static CVRP(20), DGT's state features (capacity used, progress, distance from depot) do not offer a decisive advantage and may complicate optimization unless well-tuned.
\end{enumerate}

\section{Actionable Recommendations}
\subsection{Make GT/DGT encoders edge-aware}
Add a distance-based bias $b_{ij}$ to encoder attention logits. Practical options:
\begin{itemize}[leftmargin=*]
  \item Learn an embedding $e_{ij}=\phi(\text{dist}_{ij})$ and add $w^\top e_{ij}$ to the attention score.
  \item Bucket distances (relative positional encoding style) and learn a table of biases.
  \item Concatenate $e_{ij}$ into $Q/K$ computations and project back to a scalar bias.
\end{itemize}

\subsection{Stabilize RL}
\begin{itemize}[leftmargin=*]
  \item Switch from REINFORCE to \textbf{actor--critic} (add a value head); retain entropy regularization with a nonzero floor.
  \item Consider larger batch sizes and reward normalization to reduce gradient variance.
  \item Use a slower temperature annealing for GT/DGT.
\end{itemize}

\subsection{Warm-start with imitation}
Train a few epochs with cross-entropy on heuristic/OR-Tools routes (teacher forcing), then fine-tune with RL. Transformers benefit more from pretraining given their capacity.

\subsection{Where to demonstrate advantages}
\begin{itemize}[leftmargin=*]
  \item \textbf{Larger N (50/100):} Transformers typically scale better; evaluate greedy and beam search.
  \item \textbf{Dynamic/online variants:} Demand noise, partial revelation, or time windows to surface DGT's strengths.
  \item \textbf{Decoding:} Multi-sampling or small beam often helps Transformers more than GAT.
\end{itemize}

\section{Short Experimental Plan}
\begin{enumerate}[leftmargin=*]
  \item Implement edge-biased attention in GT/DGT encoders.
  \item Add actor--critic training option and keep entropy $>0$.
  \item Reproduce N=20/50/100 with identical budgets; report train/val curves and final costs.
  \item Add imitation warm-start ablation.
  \item Evaluate dynamic CVRP variants to highlight DGT.
\end{enumerate}

\section{Frequently Asked Questions}
\paragraph{Q: Does GT/DGT “have no attention”?}
\textbf{A: They do have attention over nodes.} The difference is that encoder attention weights are computed from node embeddings alone (no edge-aware bias). Distances are still used later in decoding. GAT injects distances \emph{inside} the encoder attention, which better aligns with routing costs.

\paragraph{Q: Why is validation lower than training for all models?}
Training uses \emph{sampling} (exploration); validation uses \emph{greedy} (exploitation). Exploration produces higher costs during training---this is normal and even desirable in RL.

\section{Pointers to Literature}
\begin{itemize}[leftmargin=*]
  \item Kool et al. (2019), ``Attention, Learn to Solve Routing Problems'': Transformer decoders for routing; scaling to larger N and active search/beam methods.
  \item Nazari et al. (2018), ``Reinforcement Learning for Solving the Vehicle Routing Problem'': Pointer-style decoder with RL; masking and variance reduction.
  \item Deudon et al. (2018), ``Learning Heuristics for the TSP by Policy Gradient'': Early attention + policy gradient successes with pretraining.
  \item Joshi et al. (2019/2020), ``Learning TSP via GNNs'': Edge-aware inductive biases matter for combinatorial optimization on graphs.
\end{itemize}

\section*{Appendix: Additional Numbers}
\begin{table}[h]
  \centering
  \caption{Start, end, min, max for train/val (from current CSVs).}
  \label{tab:extra}
  \begin{tabular}{lrrrrr}
    \toprule
    Model & Split & Start & End & Min & Max \\
    \midrule
    GAT+RL & Train & 0.6662 & 0.6423 & 0.6387 & 0.6662 \\
           & Val   & 0.6101 & 0.4835 & 0.4835 & 0.6101 \\
    DGT+RL & Train & 0.6644 & 0.6421 & 0.6359 & 0.6644 \\
           & Val   & 0.6116 & 0.5504 & 0.5322 & 0.6255 \\
    GT+RL  & Train & 0.6660 & 0.6524 & 0.6465 & 0.6660 \\
           & Val   & 0.6117 & 0.5597 & 0.5464 & 0.6176 \\
    \bottomrule
  \end{tabular}
\end{table}

\end{document}

