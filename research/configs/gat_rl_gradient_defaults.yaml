# Gradient search default configuration for GAT+RL on CVRP-20
# This file centralizes all parameters. Use the tracking CSV to override the six tuned fields per iteration.

metadata:
  name: gat_rl_gradient_defaults
  version: 1
  description: Default baseline config for gradient search around GAT+RL

problem:
  type: CVRP
  num_customers: 20
  vehicle_capacity: 30
  coordinate_distribution: uniform  # uniform over [0, coord_range]
  coord_range: 100                  # scalar -> uniform [0, 100]
  demand_range: [1, 10]            # inclusive range for customer demand

experiment:
  output_root: results/gradient_search
  random_seed: 42

training:
  num_instances: 4096
  batch_size: 512
  num_epochs: 128
  learning_rate: 1.0e-4      # tuned via CSV overrides
  validation_frequency: 8

training_advanced:
  early_stopping_patience: 25
  gradient_accumulation: 1
  max_grad_norm: 1.0
  weight_decay: 1.0e-4
  lr_schedule_type: cosine   # constant|linear|cosine
  lr_warmup_steps: auto      # interpret in code as 2â€“3% of total steps if 'auto'

optimizer:
  type: AdamW
  betas: [0.9, 0.99]
  eps: 1.0e-8

rl:
  algorithm: PPO              # if applicable
  ppo_clip_range: 0.2
  entropy_coef: 0.005
  value_coef: 0.5
  gamma: 0.99
  gae_lambda: 0.95

model:
  architecture: GAT
  input_dim: 3                # x, y, demand
  hidden_dim: 128             # tuned via CSV overrides: embed_dim
  num_heads: 8                # tuned via CSV overrides: n_heads
  num_layers: 4               # tuned via CSV overrides: n_layers_enc
  transformer_dropout: 0.10   # tuned via CSV overrides: dropout
  attn_dropout: 0.00          # tuned via CSV overrides
  feedforward_multiplier: 4
  edge_embedding_divisor: 8

inference:
  default_temperature: 1.0
  greedy_evaluation: true
  max_steps_multiplier: 2
  attention_temperature_scaling: 0.5
  log_prob_epsilon: 1e-12
  masked_score_value: -1e9

logging:
  level: INFO
  format: '%(message)s'
  save_checkpoints: true
  checkpoint_every: 16

