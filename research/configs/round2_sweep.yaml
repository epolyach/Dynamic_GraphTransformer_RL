# Round 2 hyperparameter sweep focused around GAT+RL best settings
# Avoids model-specific unusable params and centers ranges for transfer to GT/DGT

name: cvrp20_round2_exploit
working_dir_path: "results/round2_sweep"

# Fixed problem setup (must match trainers)
problem:
  num_customers: 20
  vehicle_capacity: 30
  coord_range: 100
  demand_range: [1, 9]

# Base training config defaults (overridden by sweep params)
training:
  num_instances: 4096
  batch_size: 512
  num_epochs: 128
  learning_rate: 0.0005
  validation_frequency: 8

training_advanced:
  use_adaptive_temperature: true
  temp_start: 5.0
  temp_min: 0.02
  temp_adaptation_rate: 0.15
  entropy_coef: 0.003
  gradient_clip_norm: 1.5

model:
  input_dim: 3
  hidden_dim: 128
  num_heads: 8
  num_layers: 4
  transformer_dropout: 0.1
  feedforward_multiplier: 4
  edge_embedding_divisor: 8

experiment:
  random_seed: 42

# Sweep specification
sweep:
  # Models to evaluate
  models: ["GAT+RL", "GT+RL", "DGT+RL"]

  # Seeds per trial for robustness
  seeds: [42, 43, 44]

  # Marginality check around the single best (GAT only)
  gat_marginality:
    enable: true
    lr_scale: [0.5, 1.0, 2.0]
    entropy_scale: [0.5, 1.0, 1.5]
    batch_options: [256, 512, 1024]
    grad_clip_options: [1.0, 1.5, 2.0]
    attn_dropout_options: [0.1, 0.2, 0.3]
    n_layers_delta: [-1, 0, 1]
    tanh_clip_options: [10, 15, 20]

  # Focused parameter grids for all models (trainer-side, architecture-agnostic)
  grid:
    embedding_dim: [128, 192, 256]
    n_layers: [3, 4, 5, 6]
    n_heads: [8]   # kept fixed for stability; validated to divide embedding_dim
    learning_rate: [0.00025, 0.00035, 0.0005]
    dropout: [0.0, 0.1, 0.2]
    batch_size: [256, 512, 1024]
    temp_start: [5.0]
    temp_min: [0.02]
    temp_decay: [0.15]

  # Optional GT/DGT-only extras (applied only if trainer/model supports them)
  conditionals:
    distance_encoding_strength: {models: ["GT+RL", "DGT+RL"], values: [0.3, 0.6, 1.0]}
    dynamic_state_updates_per_decode: {models: ["DGT+RL"], values: [1, 2, 3]}
    state_update_type: {models: ["DGT+RL"], values: ["gru", "mlp"]}

