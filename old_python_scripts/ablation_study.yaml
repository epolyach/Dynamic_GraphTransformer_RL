# Ablation Study Configuration
# Defines experiments for comparing three model variants:
# 0. Baseline: Greedy Graph Transformer
# 1. Static RL: Graph Transformer + RL
# 2. Dynamic RL: Full pipeline with dynamic updates

# Experiment Setup
experiment:
  name: "ablation_study_graph_transformer"
  description: "Comparison of Graph Transformer variants for CVRP"
  variants:
    - "0_baseline"    # Greedy Graph Transformer
    - "1_static_rl"   # Static RL
    - "2_dynamic_rl"  # Dynamic RL
  
  # Problem sizes for evaluation
  problem_sizes: [20, 50, 100, 200]
  
  # Number of test instances per size
  num_test_instances: 100
  
  # Number of runs per instance (for statistical significance)
  num_runs: 5

# Shared Model Configuration
model:
  # Graph Transformer Encoder (shared across all variants)
  encoder:
    node_input_dim: 3  # x, y, demand
    edge_input_dim: 1  # distance
    hidden_dim: 128
    num_heads: 8
    num_layers: 6
    dropout: 0.1
    activation: "relu"
    
  # Positional Encodings
  positional_encoding:
    pe_type: "sinusoidal"
    max_distance: 100.0
    pe_dim: 64
    
  # Dynamic Graph Updates (for variant 2 only)
  dynamic_updates:
    enabled: true
    update_frequency: 1  # Update every step
    update_node_features: true
    update_edge_weights: true
    adaptive_masking: true

# Training Configuration
training:
  # Different training setups for different variants
  variants:
    "0_baseline":
      # No training needed - greedy policy
      requires_training: false
      epochs: 0
      
    "1_static_rl":
      # Standard RL training
      requires_training: true
      epochs: 100
      batch_size: 512
      learning_rate: 1e-4
      curriculum_learning: true
      
    "2_dynamic_rl":
      # RL training with dynamic updates
      requires_training: true
      epochs: 100
      batch_size: 256  # Smaller batch due to dynamic updates complexity
      learning_rate: 1e-4
      curriculum_learning: true
      
  # Shared RL parameters
  rl:
    algorithm: "reinforce"
    baseline: "rollout"
    entropy_weight: 0.01
    gamma: 0.99
    
  # Curriculum learning
  curriculum:
    start_size: 20
    end_size: 200
    growth_rate: 1.1
    growth_frequency: 10

# Problem Settings
problem:
  name: "cvrp"
  vehicle_capacity: 50
  depot_location: "center"
  node_distribution: "uniform"
  demand_range: [1, 10]
  coordinate_range: [0, 100]

# Evaluation Metrics
evaluation:
  metrics:
    - "solution_cost"           # Primary metric: total routing distance
    - "optimality_gap"         # Gap vs best known solution (if available)
    - "computation_time"       # Time to generate solution
    - "memory_usage"          # Peak memory consumption
    - "convergence_steps"     # Steps to find solution
    
  # Baselines for comparison
  baselines:
    - "nearest_neighbor"       # Simple greedy baseline
    - "clark_wright"          # Classical heuristic
    - "or_tools"              # Google OR-Tools solver (if available)
    
  # Statistical analysis
  statistical_tests:
    - "paired_t_test"         # Compare variants pairwise
    - "wilcoxon_signed_rank"  # Non-parametric alternative
    - "friedman_test"         # Multiple comparisons

# Hardware Configuration
hardware:
  device: "auto"  # Use GPU if available
  num_workers: 4
  pin_memory: true
  
# Logging and Output
logging:
  log_level: "INFO"
  save_results: true
  results_dir: "experiments/ablation_study"
  
  # What to log for each variant
  log_details:
    "0_baseline":
      - "greedy_decisions"
      - "routing_quality"
      
    "1_static_rl":
      - "training_curves"
      - "policy_convergence"
      - "action_probabilities"
      
    "2_dynamic_rl":
      - "dynamic_updates"
      - "graph_evolution"
      - "attention_patterns"
      - "state_tracking"

# Visualization
visualization:
  generate_plots: true
  plot_types:
    - "performance_comparison"    # Bar charts comparing variants
    - "scalability_analysis"     # Performance vs problem size
    - "convergence_curves"       # Training curves (for RL variants)
    - "solution_visualization"   # Sample route visualizations
    - "attention_heatmaps"       # Attention pattern analysis
    
  save_formats: ["png", "pdf"]

# Analysis Configuration
analysis:
  # Contribution analysis
  compute_contributions:
    "graph_transformer_vs_gat": true      # Architecture improvement
    "rl_vs_greedy": true                  # RL training benefit
    "dynamic_vs_static": true             # Dynamic updates benefit
    
  # Ablation analysis
  ablation_components:
    - "positional_encoding"               # Effect of PE types
    - "attention_heads"                   # Number of heads analysis  
    - "transformer_layers"               # Depth analysis
    - "update_frequency"                 # Dynamic update frequency
    
  # Performance analysis
  performance_analysis:
    - "parameter_efficiency"             # Performance per parameter
    - "computational_complexity"        # Time/space complexity
    - "memory_profiling"                # Detailed memory usage
    - "scalability_limits"              # Maximum problem size
