% Requires: \usepackage{booktabs, array, adjustbox}

\begin{table}[htbp]
\centering
\adjustbox{width=\textwidth}{%
\begin{tabular}{@{}l|ccccc@{}}
\toprule
\textbf{Parameter} & \textbf{Tiny} & \textbf{Small} & \textbf{Medium} & \textbf{Large} & \textbf{Huge} \\
\midrule
\multicolumn{6}{c}{\textbf{Problem Configuration}} \\
\midrule
Number of customers & 10 & 10 & 20 & 50 & 100 \\
Vehicle capacity & 20 & 20 & 30 & 40 & 50 \\
\midrule
\multicolumn{6}{c}{\textbf{Graph Transformer (GT/DGT) Architecture}} \\
\midrule
Hidden dimension & 128 & 128 & 256$^{\dagger}$ & 512 & 512 \\
Number of heads & 4$^{\dagger}$ & 4$^{\dagger}$ & 4$^{\dagger}$ & 8 & 8 \\
Number of layers & 3 & 3 & 4$^{\dagger}$ & 6 & 8 \\
Transformer dropout & 0.1$^{\dagger}$ & 0.1$^{\dagger}$ & 0.1$^{\dagger}$ & 0.15 & 0.2 \\
Feedforward multiplier & 2$^{\dagger}$ & 2$^{\dagger}$ & 2$^{\dagger}$ & 2$^{\dagger}$ & 2$^{\dagger}$ \\
\midrule
\multicolumn{6}{c}{\textbf{GAT Architecture}} \\
\midrule
GAT hidden dimension & 128 & 128 & 256$^{\dagger}$ & 512 & 512 \\
GAT layers & 3 & 3 & 4$^{\dagger}$ & 5 & 6 \\
GAT dropout & 0.6$^{\dagger}$ & 0.6$^{\dagger}$ & 0.6$^{\dagger}$ & 0.5 & 0.5 \\
GAT edge dimension & 16$^{\dagger}$ & 16$^{\dagger}$ & 16$^{\dagger}$ & 16$^{\dagger}$ & 16$^{\dagger}$ \\
GAT negative slope & 0.2$^{\dagger}$ & 0.2$^{\dagger}$ & 0.2$^{\dagger}$ & 0.2$^{\dagger}$ & 0.2$^{\dagger}$ \\
\midrule
\multicolumn{6}{c}{\textbf{Model Parameter Counts}} \\
\midrule
GAT total parameters & 320K & 320K & 1.28M & 6.83M & 10.2M \\
GT total parameters & 780K & 780K & 3.12M & 19.9M & 31.9M \\
DGT total parameters & 1.77M & 1.77M & 7.09M & 45.3M & 72.5M \\
\midrule
\multicolumn{6}{c}{\textbf{Training Configuration}} \\
\midrule
Batches per epoch$^{*}$ & 15 & 1500$^{\dagger}$ & 1500$^{\dagger}$ & 1500$^{\dagger}$ & 1500$^{\dagger}$ \\
Batch size & 64 & 512$^{\dagger}$ & 512$^{\dagger}$ & 512$^{\dagger}$ & 512$^{\dagger}$ \\
Number of epochs & 100$^{\dagger}$ & 100$^{\dagger}$ & 100$^{\dagger}$ & 100$^{\dagger}$ & 100$^{\dagger}$ \\
Learning rate & $10^{-4\dagger}$ & $10^{-4\dagger}$ & $10^{-4\dagger}$ & $10^{-4\dagger}$ & $10^{-4\dagger}$ \\
\midrule
\multicolumn{6}{c}{\textbf{Advanced Training (for Large/Huge)}} \\
\midrule
Early stopping patience & 10$^{\dagger}$ & 10$^{\dagger}$ & 10$^{\dagger}$ & 10$^{\dagger}$ & 40 \\
Gradient clip norm & 2.0$^{\dagger}$ & 2.0$^{\dagger}$ & 2.0$^{\dagger}$ & 2.0$^{\dagger}$ & 1.5 \\
\bottomrule
\end{tabular}%
}
\caption{Configuration parameters for different problem scales in the Dynamic Graph Transformer RL framework. Values marked with $^{\dagger}$ represent default values from \texttt{default.yaml}. The tiny configuration uses reduced training data ($^{*}$batches per epoch = 15) for rapid experimentation, while other configurations use the full training regime. Model parameter counts are calculated based on the respective architectures: GAT (Graph Attention Network), GT (Graph Transformer), and DGT (Dynamic Graph Transformer).}
\label{tab:config_comparison}
\end{table}
