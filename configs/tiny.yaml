# Tiny config - Quick experiments with reduced training
# Same problem as small (N=10) but reduced training data
working_dir_path: "../results/tiny"

problem:
  num_customers: 10
  vehicle_capacity: 20

training:
  num_batches_per_epoch: 1500  # Paper's scale: 768,000 instances per epoch
  batch_size: 512             # Default batch size (paper's value)
  num_epochs: 60             # Default number of epochs

# Smaller model for faster training
model:
  hidden_dim: 128              # Half of default 256
  num_heads: 4
  num_layers: 3                # Reduced from default 4

# GAT-specific architecture for tiny experiments
model_gat:
  gat_hidden_dim: 128          # Smaller for quick experiments
  gat_layers: 3                # Fewer layers for speed

# Optimized baseline settings
baseline:
  type: "rollout"
  eval_batches: 2           # Reduced for faster evaluation
  update:
    enabled: true
    frequency: 2            # Update every 2 epochs
    significance_test: true
    p_value: 0.10

# Experiment settings
experiment:
  random_seed: 42
  device: "cuda"
  use_advanced_features: true
  strict_validation: false  # Disabled for speed

# GPU Configuration
gpu:
  enabled: true
  device: "cuda:0"
  mixed_precision: false    # Disabled for N=10 (overhead > benefit)
  memory_fraction: 0.95
  pin_memory: false
  non_blocking: true
  gradient_accumulation_steps: 1
  num_workers: 0           # 0 for small problems
  prefetch_factor: 2
