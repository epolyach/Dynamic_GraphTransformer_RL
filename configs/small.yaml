# Small-scale configuration: quick experiments overriding only study-relevant params
working_dir_path: "results/small"

problem:
  num_customers: 10

training:
  num_batches_per_epoch: 15  # 15 batches per epoch  
  batch_size: 512         
  num_epochs: 100
  learning_rate: 0.0001 

# Override for better algorithm differentiation
training_advanced:
  # Longer patience for better convergence
  early_stopping_patience: 25  # Increased to match longer training
  
  # More aggressive temperature adaptation for clear differences  
  temp_start: 3.5          # Even higher start
  temp_min: 0.05           # Even lower min
  temp_adaptation_rate: 0.25   # Faster adaptation

# Keep default cost penalty modest to speed learning signal; override if studying penalties
cost:
  depot_penalty_per_visit: 0.0

