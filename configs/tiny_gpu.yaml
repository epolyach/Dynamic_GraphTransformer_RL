# Tiny GPU config - Quick experiments with GPU training
working_dir_path: "training_gpu/results/tiny"

problem:
  num_customers: 10
  vehicle_capacity: 20

training:
  batches_per_epoch: 10        # Small for quick testing
  batch_size: 64               # Reasonable batch size for GPU
  n_epochs: 5                  # Few epochs for testing
  baseline:                    # Baseline config nested under training
    eval_batches: 2            # Small number for quick evaluation
    update_frequency: 2        # Update every 2 epochs
    warmup_epochs: 0           # No warmup for quick testing

# GPU-specific settings
gpu:
  enabled: true
  device: "cuda:0"             # Use first GPU
  mixed_precision: false       # Disabled for stability during testing
  memory_fraction: 0.95        # Use most of GPU memory
  pin_memory: true            
  non_blocking: true          
  gradient_accumulation_steps: 1
  num_workers: 4              
  prefetch_factor: 2          

# Smaller model for faster training
model:
  hidden_dim: 128              # Half of default 256
  num_heads: 4
  num_layers: 3                # Reduced from default 4

# GAT-specific architecture for tiny experiments
model_gat:
  gat_hidden_dim: 128          # Smaller for quick experiments
  gat_layers: 3                # Fewer layers for speed
