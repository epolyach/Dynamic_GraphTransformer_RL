# Tiny GPU config - Larger batch size and more steps for GPU training
# Batch size 3072, 25 steps per epoch
working_dir_path: "../results/tiny_gpu_512_fixed_temp"

problem:
  num_customers: 10
  vehicle_capacity: 30

training:
  num_batches_per_epoch: 75   # 150 steps per epoch
  batch_size: 1024              # Large batch size for GPU
  num_epochs: 100              # Default number of epochs

# Smaller model for faster training
model:
  hidden_dim: 128              # Half of default 256
  num_heads: 4
  num_layers: 3                # Reduced from default 4

# Baseline configuration for efficient training
baseline:
  eval_batches: 1              # Small eval dataset
  update:
    frequency: 2               # Update every 2 epochs
    warmup_epochs: 0

# Optional: specify inference settings
inference:
  max_steps_multiplier: 10
  default_temperature: 2.5

# Override temperature settings - fixed at 2.5, no annealing
training_advanced:
  use_adaptive_temperature: false  # Disable adaptive temperature
  temp_start: 2.5                  # Fixed temperature
  temp_min: 2.5                    # Same as start (no annealing)
