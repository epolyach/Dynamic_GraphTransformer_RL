# Default configuration loaded first and deep-merged with any provided config
# Put all stable/tuning parameters here. Per-experiment configs override only what they study.

# Working directory (will usually be overridden by scale-specific config)
working_dir_path: "results/default"

# =============================
# Core CVRP problem parameters
# =============================
problem:
  num_customers: 20        # Default customers (excluding depot)
  vehicle_capacity: 30     # Integer capacity
  demand_range: [1, 10]    # Integer demands [min, max]
  coord_range: 100         # Coordinates 0..coord_range, then normalized to [0,1]

# =============================
# Training parameters
# =============================
training:
  num_instances: 4096      # Default dataset size
  batch_size: 128          # Default batch size
  num_epochs: 32           # Default number of epochs
  learning_rate: 5e-5      # Base LR
  train_val_split: 0.8     # Train/val split
  validation_frequency: 4  # Run validation every N epochs

# =============================
# Experiment control
# =============================
experiment:
  random_seed: 42
  device: "cpu"
  strict_validation: false
  use_advanced_features: true

# =============================
# Model architecture (shared)
# =============================
model:
  input_dim: 3
  hidden_dim: 256
  num_heads: 4
  num_layers: 4
  transformer_dropout: 0.1
  feedforward_multiplier: 2
  edge_embedding_divisor: 4

  pointer_network:
    input_multiplier: 2
    context_multiplier: 2
    output_dim: 1

  dynamic_graph_transformer:
    state_features: 4
    residual_gate_init: -2.19722458
    update_input_multiplier: 2
    update_activation: "relu"

  graph_transformer:
    input_multiplier: 2
    output_dim: 1

  graph_attention_transformer:
    input_multiplier: 2
    output_dim: 1

  legacy_gat:
    node_input_dim: 3
    edge_input_dim: 1
    hidden_dim: 128
    edge_dim: 16
    num_layers: 4
    negative_slope: 0.2
    dropout: 0.6

# === NEW ENHANCED FEATURES ===
training_advanced:
  # Better optimizer
  optimizer: "AdamW"
  weight_decay: 0.0001
  gradient_clip_norm: 2.0
  
  # Learning rate scheduling  
  use_lr_scheduling: true
  scheduler_type: "cosine"
  min_lr: 0.000001
  
  # Early stopping
  use_early_stopping: true
  early_stopping_patience: 10
  early_stopping_delta: 0.0001
  
  # Better entropy scheduling
  entropy_coef: 0.02
  entropy_min: 0.001
  
  # Adaptive temperature scheduling (optimized for differentiation)
  use_adaptive_temperature: true
  temp_start: 3.0          # Higher start for more exploration
  temp_min: 0.1            # Lower min for more exploitation contrast
  temp_adaptation_rate: 0.2    # Faster adaptation for clearer differences
  
  # Enhanced RL parameters for better differentiation
  entropy_decay_start: 5   # When to start entropy decay
  advantage_normalization: true  # Normalize advantages for stability


# =============================
# System / CPU optimization
# =============================
system:
  cpu_optimization:
    auto_detect_threads: true
    max_threads: null
    inter_op_threads_divisor: 4
  openmp_settings:
    kmp_blocktime: "0"
    kmp_settings: "0"
    kmp_affinity: "granularity=fine,compact,1,0"

# =============================
# Inference and evaluation
# =============================
inference:
  default_temperature: 1.0
  greedy_evaluation: true
  max_steps_multiplier: 2
  attention_temperature_scaling: 0.5
  log_prob_epsilon: 1e-12
  masked_score_value: -1e9

# =============================
# Cost settings
# =============================
cost:
  depot_penalty_per_visit: 0.0

# =============================
# Output paths
# =============================
output:
  results_base_dir: "results"
  subdirectories:
    pytorch: "pytorch"
    analysis: "analysis"
    logs: "logs"
    csv: "csv"
    checkpoints: "checkpoints"
  legacy_paths:
    checkpoints: "legacy_checkpoints"
    training_logs: "logs/training"
    checkpoint_name: "actor.pt"

# =============================
# Logging
# =============================
logging:
  level: "INFO"
  format: "%(message)s"
  progress_bars: true

