#!/usr/bin/env python3
"""
Debug script to examine routes generated by TRAINED Baseline Pointer Network
"""

import torch
import numpy as np
import sys

from run_comparative_study import (
    BaselinePointerNetwork, generate_cvrp_instance, 
    compute_route_cost, compute_naive_baseline_cost,
    validate_route, set_seeds
)

def debug_trained_pointer():
    """Debug routes from trained model"""
    print("ðŸ” DEBUGGING TRAINED BASELINE POINTER NETWORK")
    print("=" * 50)
    
    set_seeds(42)
    
    # Load the trained model
    try:
        checkpoint = torch.load('model_baseline_pointer.pt', map_location='cpu', weights_only=False)
        model = BaselinePointerNetwork(input_dim=3, hidden_dim=64)
        model.load_state_dict(checkpoint['model_state_dict'])
        print("âœ… Loaded trained Baseline Pointer model")
    except FileNotFoundError:
        print("âŒ No trained model found. Please run the comparative study first.")
        return
    
    # Generate validation instances (same way as in training)
    print("\nðŸ“Š ANALYZING TRAINED MODEL ON VALIDATION INSTANCES:")
    print("-" * 60)
    
    # Generate same instances as in training (seeds 640-799 for validation)
    val_instances = []
    for i in range(640, 650):  # Just first 10 validation instances
        instance = generate_cvrp_instance(
            num_customers=6, capacity=3, coord_range=50, 
            demand_range=(1, 3), seed=i
        )
        val_instances.append(instance)
    
    total_naive_cost = 0
    total_model_cost = 0
    violations = []
    
    model.eval()
    with torch.no_grad():
        for i, instance in enumerate(val_instances):
            print(f"\nðŸ”¸ VALIDATION INSTANCE {i} (seed={640+i}):")
            
            # Calculate naive baseline
            naive_cost = compute_naive_baseline_cost(instance)
            naive_normalized = naive_cost / 6
            
            # Generate route with trained model
            routes, _ = model([instance], greedy=True)
            route = routes[0]
            
            # Validate route
            validate_route(route, 6, f"TRAINED-DEBUG-{i}")
            
            # Calculate model cost
            model_cost = compute_route_cost(route, instance['distances'])
            model_normalized = model_cost / 6
            
            print(f"   Naive:  {naive_cost:.2f} total ({naive_normalized:.4f}/cust)")
            print(f"   Trained: {model_cost:.2f} total ({model_normalized:.4f}/cust)")
            print(f"   Route: {route}")
            
            if model_cost > naive_cost:
                excess = model_cost - naive_cost
                excess_norm = model_normalized - naive_normalized
                print(f"   ðŸš¨ VIOLATION: +{excess:.2f} total (+{excess_norm:.4f}/cust)")
                violations.append({
                    'instance': i,
                    'seed': 640 + i,
                    'naive_cost': naive_cost,
                    'model_cost': model_cost,
                    'excess': excess,
                    'route': route
                })
                
                # Detailed analysis of the violation
                print("   ðŸ” VIOLATION ANALYSIS:")
                print(f"      This route is doing: {route}")
                print(f"      Instead of naive approach...")
                
            elif model_cost == naive_cost:
                print("   âš ï¸  EQUAL to naive (no learning)")
            else:
                improvement = naive_cost - model_cost
                print(f"   âœ… Better by {improvement:.2f} total ({improvement/6:.4f}/cust)")
            
            total_naive_cost += naive_cost
            total_model_cost += model_cost
    
    # Summary
    print("\n" + "=" * 60)
    print("ðŸ“‹ TRAINED MODEL ANALYSIS SUMMARY:")
    print(f"Instances analyzed: {len(val_instances)}")
    print(f"Total naive cost: {total_naive_cost:.2f}")
    print(f"Total trained cost: {total_model_cost:.2f}")
    print(f"Average naive cost/customer: {total_naive_cost / (len(val_instances) * 6):.4f}")
    print(f"Average trained cost/customer: {total_model_cost / (len(val_instances) * 6):.4f}")
    print(f"Violations found: {len(violations)}")
    
    if violations:
        print(f"\nðŸš¨ {len(violations)} VIOLATIONS DETECTED:")
        for v in violations:
            print(f"   Instance {v['instance']} (seed {v['seed']}): +{v['excess']:.2f} excess")
            print(f"   Route: {v['route']}")
    
    if total_model_cost > total_naive_cost:
        total_excess = total_model_cost - total_naive_cost
        print(f"\nðŸš¨ OVERALL: Trained model is {total_excess:.2f} WORSE than naive!")
        print("This confirms the bug exists in the trained model.")
    else:
        print(f"\nâœ… Overall: Trained model is {total_naive_cost - total_model_cost:.2f} better than naive")

if __name__ == "__main__":
    debug_trained_pointer()
