"""
GPU-Optimized Advanced Trainer for CVRP Models (SIMPLIFIED VERSION)

This module provides GPU-optimized training functionality for:
- GAT (Graph Attention Network)
- GT (Graph Transformer)
- DGT (Dynamic Graph Transformer)

Key optimizations:
- Mixed precision training (FP16/FP32)
- Efficient batch processing on GPU
- Non-blocking data transfers
- Gradient accumulation
- Memory management

SIMPLIFIED: Removed overengineering and unnecessary abstractions
"""

import os
import time
import copy
import logging
from typing import Dict, Any, List, Tuple, Optional, Callable
from collections import defaultdict
from pathlib import Path

import numpy as np
import torch
import torch.nn as nn
import torch.optim as optim
from torch.optim.lr_scheduler import CosineAnnealingLR, ReduceLROnPlateau
from torch.utils.data import DataLoader
from torch.amp import autocast, GradScaler

from src.metrics.costs import compute_route_cost
from src.metrics.gpu_costs import compute_route_cost_gpu, compute_route_cost_vectorized
from .validation_gpu import validate_route
from .rollout_baseline_gpu_fixed import RolloutBaselineGPU
from .gpu_utils import GPUManager, DataLoaderGPU

logger = logging.getLogger(__name__)


# ==============================================================================
# SIMPLIFIED HELPER FUNCTIONS
# ==============================================================================
def compute_cpc(costs, n_customers, use_geometric_mean=False, device=None):
    """
    Compute Cost Per Customer (CPC) with specified aggregation.
    
    Args:
        costs: Tensor of route costs [batch_size]
        n_customers: Number of customers (can be int, list, or tensor)
        use_geometric_mean: Whether to use geometric mean instead of arithmetic
        device: Device for tensor operations
    
    Returns:
        Scalar CPC value
    """
    # Handle different input types for n_customers
    if isinstance(n_customers, int):
        # Single value for all instances
        n_cust_tensor = n_customers
    elif isinstance(n_customers, (list, tuple, np.ndarray)):
        # Convert to tensor only when needed
        n_cust_tensor = torch.tensor(n_customers, device=device or costs.device, dtype=costs.dtype)
    else:
        # Already a tensor
        n_cust_tensor = n_customers
    
    if use_geometric_mean:
        # Geometric mean: exp(mean(log(cost/n_customers)))
        cpc_logs = torch.log(costs + 1e-10) - torch.log(n_cust_tensor + 1e-10)
        return torch.exp(cpc_logs.mean())
    else:
        # Arithmetic mean
        return (costs / n_cust_tensor).mean()


# ==============================================================================
# SIMPLIFIED TEMPERATURE SCHEDULER
# ==============================================================================
class SimpleTemperatureScheduler:
    """Linear or exponential temperature decay scheduler."""
    
    def __init__(self, start=2.0, end=0.5, total_epochs=100, mode='linear'):
        self.start = start
        self.end = end
        self.total_epochs = total_epochs
        self.mode = mode
    
    def get_temp(self, epoch):
        """Get temperature for current epoch."""
        if epoch >= self.total_epochs:
            return self.end
            
        progress = epoch / self.total_epochs
        
        if self.mode == 'linear':
            return self.start + (self.end - self.start) * progress
        elif self.mode == 'exponential':
            return self.start * (self.end / self.start) ** progress
        else:
            raise ValueError(f"Unknown mode: {self.mode}")


# ==============================================================================
# SIMPLIFIED EARLY STOPPING
# ==============================================================================
class EarlyStopping:
    """Simplified early stopping utility."""
    
    def __init__(self, patience: int = 10, min_delta: float = 1e-4):
        self.patience = patience
        self.min_delta = min_delta
        self.best_score = None
        self.counter = 0
        self.best_weights = None
        
    def __call__(self, val_score: float, model: nn.Module) -> bool:
        """Returns True if training should stop."""
        if self.best_score is None:
            self.best_score = val_score
            self.best_weights = copy.deepcopy(model.state_dict())
        elif val_score < self.best_score - self.min_delta:
            self.best_score = val_score
            self.counter = 0
            self.best_weights = copy.deepcopy(model.state_dict())
        else:
            self.counter += 1
            
        return self.counter >= self.patience
    
    def restore_best_weights(self, model: nn.Module):
        """Restore best weights to model."""
        if self.best_weights is not None:
            model.load_state_dict(self.best_weights)


def advanced_train_model_gpu(
    model: nn.Module,
    model_name: str,
    data_generator: Any,
    config: Dict[str, Any],
    device: Optional[torch.device] = None,
    checkpoint_dir: Optional[Path] = None,
    callbacks: Optional[List[Callable]] = None,
    use_wandb: bool = False
) -> Tuple[nn.Module, Dict[str, Any]]:
    """
    Advanced GPU training with multiple optimizations (SIMPLIFIED VERSION).
    
    Args:
        model: Model to train
        data_generator: Function that generates training instances
        num_instances: Total number of training instances
        batch_size: Batch size for training
        num_epochs: Number of epochs to train
        learning_rate: Initial learning rate
        lr_schedule: Learning rate schedule ('cosine', 'plateau', or None)
        save_dir: Directory to save checkpoints
        checkpoint_interval: Interval for saving checkpoints
        config: Additional configuration
        baseline: Baseline for RL training
        early_stopping: Whether to use early stopping
        early_stopping_patience: Patience for early stopping
        load_checkpoint: Path to checkpoint to load
        mean_type: 'geometric' or 'arithmetic' for CPC aggregation
        
    Returns:
        Tuple of (trained_model, training_metrics)
    """
    logger.info("[INIT] Starting advanced GPU training (SIMPLIFIED)")
    
    # Extract parameters from config
    train_config = config.get("training", {})
    gpu_config = config.get("gpu", {})
    adv_config = config.get("training_advanced", {})
    
    # Training parameters
    num_epochs = train_config.get("num_epochs", 100)
    batch_size = train_config.get("batch_size", 32)
    learning_rate = train_config.get("learning_rate", 1e-4)
    num_batches_per_epoch = train_config.get("num_batches_per_epoch", 100)
    num_instances = num_batches_per_epoch * batch_size
    lr_schedule = train_config.get("lr_schedule", "cosine")
    checkpoint_interval = train_config.get("checkpoint_interval", 10)
    save_dir = checkpoint_dir
    
    # Advanced training parameters
    mean_type = adv_config.get("mean_type", "arithmetic")
    use_geometric_mean = (mean_type == "geometric")
    early_stopping = adv_config.get("early_stopping", False)
    early_stopping_patience = adv_config.get("early_stopping_patience", 10)
    accumulation_steps = gpu_config.get("gradient_accumulation_steps", 1)
    # baseline = adv_config.get("baseline", None)  # REMOVED - will create below
    load_checkpoint = adv_config.get("load_checkpoint", None)
    # Initialize GPU manager
    gpu_manager = GPUManager(
        device=device or gpu_config.get('device'),
        memory_fraction=gpu_config.get('memory_fraction', 0.95),
        enable_mixed_precision=gpu_config.get('mixed_precision', True)
    )
    
    # Move model to GPU
    model = model.to(gpu_manager.device)
    logger.info(f"Model moved to GPU:{gpu_manager.device}")
    
    # Initialize optimizer
    optimizer = optim.Adam(model.parameters(), lr=learning_rate)
    
    # Initialize learning rate scheduler
    scheduler = None
    if lr_schedule == 'cosine':
        scheduler = CosineAnnealingLR(optimizer, T_max=num_epochs, eta_min=learning_rate * 0.01)
    elif lr_schedule == 'plateau':
        scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=5)
    
    # Initialize gradient scaler for mixed precision
    scaler = GradScaler('cuda') if gpu_manager.enable_mixed_precision else None
    
    # Initialize early stopping
    early_stopper = EarlyStopping(patience=early_stopping_patience) if early_stopping else None
    
    # Initialize temperature scheduler (SIMPLIFIED)
    temp_scheduler = SimpleTemperatureScheduler(
        start=config.get('temp_start', 2.0),
        end=config.get('temp_end', 0.5),
        total_epochs=num_epochs,
        mode='linear'
    )
    
    # Initialize baseline for RL models
    baseline = None
    baseline_config = config.get('baseline', {})
    if hasattr(model, 'training_mode') and model.training_mode == 'RL':
        logger.info("[INIT] Creating RolloutBaselineGPU for RL training...")
        
        # Create eval dataset for baseline
        eval_batches = baseline_config.get('eval_batches', 5)
        logger.info(f"[INIT] Building eval dataset: eval_batches={eval_batches}, batch_size={batch_size}")
        
        baseline_eval_instances = []
        for _ in range(eval_batches):
            batch = data_generator(batch_size)
            baseline_eval_instances.append(batch)  # Keep as batches, don't extend
        
        logger.info(f"[INIT] Eval dataset built: {len(baseline_eval_instances)} batches, {len(baseline_eval_instances) * batch_size} total instances")
        
        # Create baseline
        baseline = RolloutBaselineGPU(
            gpu_manager=gpu_manager,
            model=model,
            eval_dataset=baseline_eval_instances,  # Pass batched dataset
            config=config,
            logger_print=logger.info
        )
        logger.info("[INIT] Baseline initialized")
    
    # Load checkpoint if specified
    start_epoch = 0
    if load_checkpoint and os.path.exists(load_checkpoint):
        checkpoint = torch.load(load_checkpoint, map_location=gpu_manager.device)
        model.load_state_dict(checkpoint['model_state_dict'])
        optimizer.load_state_dict(checkpoint['optimizer_state_dict'])
        start_epoch = checkpoint.get('epoch', 0) + 1
        logger.info(f"Loaded checkpoint from epoch {start_epoch - 1}")
    
    # Initialize baseline for RL if needed
    # Training metrics
    history = defaultdict(list)
    best_val_cost = float('inf')
    
    # Effective batch size for logging
    effective_batch_size = batch_size * accumulation_steps
    logger.info(f"Effective batch size: {effective_batch_size} (batch_size={batch_size}, accumulation_steps={accumulation_steps})")
    
    # Calculate batches per epoch
    batches_per_epoch = (num_instances + batch_size - 1) // batch_size
    
    # Print training configuration
    logger.info(f"[{model.model_type}] Training with {num_instances} total instances over {num_epochs} epochs")
    logger.info(f"[{model.model_type}] Batches per epoch: {batches_per_epoch}, batch size: {batch_size}")
    logger.info(f"[{model.model_type}] Using {mean_type} mean for CPC aggregation")
    
    # Training loop
    training_start = time.time()
    
    for epoch in range(start_epoch, num_epochs):
        epoch_start = time.time()
        model.train()
        
        train_loss_epoch = []
        train_cost_epoch = []
        val_cost_epoch = []
        
        # Get temperature for this epoch (SIMPLIFIED)
        current_temp = temp_scheduler.get_temp(epoch)
        
        optimizer.zero_grad()
        
        # Training batches
        for batch_idx in range(batches_per_epoch):
            # Generate batch
            instances = data_generator(batch_size)
            
            # Prepare instances for GPU
            for inst in instances:
                if 'distances' in inst:
                    inst['distances'] = torch.tensor(
                        inst['distances'], 
                        device=gpu_manager.device, 
                        dtype=torch.float32
                    )
                if 'coords' in inst:
                    inst['coords'] = torch.tensor(
                        inst['coords'],
                        device=gpu_manager.device,
                        dtype=torch.float32
                    )
            
            with autocast('cuda', enabled=gpu_manager.enable_mixed_precision):
                # Forward pass
                if hasattr(model, 'training_mode') and model.training_mode == 'RL':
                    # RL mode: decode routes and compute costs
                    routes, log_probs = model.decode(
                        instances,
                        return_log_probs=True,
                        temperature=current_temp,
                        greedy=False
                    )
                    
                    # Prepare for vectorized cost computation
                    max_len = max(len(r) for r in routes)
                    routes_padded = []
                    distances_list = []
                    for b, route in enumerate(routes):
                        padded = route + [-1] * (max_len - len(route))
                        routes_padded.append(padded)
                        distances_list.append(instances[b]["distances"])
                    
                    # Convert to tensors
                    routes_tensor = torch.tensor(routes_padded, device=gpu_manager.device, dtype=torch.long)
                    distances_batch = torch.stack(distances_list)
                    
                    # Vectorized cost computation - SIMPLIFIED
                    rcosts = compute_route_cost_vectorized(routes_tensor, distances_batch)
                    
                    # Compute CPC using helper function - SIMPLIFIED
                    n_customers = [len(inst['coords']) - 1 for inst in instances]
                    batch_cost = compute_cpc(rcosts, n_customers, use_geometric_mean, gpu_manager.device)
                    
                    # For RL training, use actual costs (not CPC) - SIMPLIFIED
                    costs_tensor = rcosts.to(dtype=torch.float32)  # No conversion needed
                    
                    # Compute baseline
                    if baseline is not None:
                        bl_vals = baseline.eval_batch(instances)
                        if bl_vals.device != costs_tensor.device:
                            bl_vals = bl_vals.to(costs_tensor.device)
                        if bl_vals.numel() != costs_tensor.numel():
                            base_scalar = costs_tensor.mean().detach()
                            advantages = base_scalar - costs_tensor
                        else:
                            advantages = bl_vals.detach() - costs_tensor
                    else:
                        base_scalar = costs_tensor.mean().detach()
                        advantages = base_scalar - costs_tensor
                    
                    # REINFORCE loss
                    loss = -(advantages * log_probs).mean()
                    
                else:
                    # Supervised mode
                    outputs = model(instances)
                    targets = torch.tensor(
                        [inst.get('target', 0) for inst in instances],
                        device=gpu_manager.device,
                        dtype=torch.float32
                    )
                    loss = nn.functional.mse_loss(outputs, targets)
                    batch_cost = loss.clone()
            
            # Backward pass with gradient accumulation
            if scaler:
                scaler.scale(loss / accumulation_steps).backward()
            else:
                (loss / accumulation_steps).backward()
            
            # Update weights
            if (batch_idx + 1) % accumulation_steps == 0:
                if scaler:
                    scaler.step(optimizer)
                    scaler.update()
                else:
                    optimizer.step()
                optimizer.zero_grad()
            
            train_loss_epoch.append(loss.item())
            train_cost_epoch.append(batch_cost.item())
            
            # Validation batch (less frequently)
            if batch_idx % max(1, batches_per_epoch // 5) == 0:
                model.eval()
                with torch.no_grad():
                    val_instances = data_generator(batch_size)
                    
                    # Prepare validation instances
                    for inst in val_instances:
                        if 'distances' in inst:
                            inst['distances'] = torch.tensor(
                                inst['distances'],
                                device=gpu_manager.device,
                                dtype=torch.float32
                            )
                        if 'coords' in inst:
                            inst['coords'] = torch.tensor(
                                inst['coords'],
                                device=gpu_manager.device,
                                dtype=torch.float32
                            )
                    
                    # Decode validation routes
                    routes_val = model.decode(
                        val_instances,
                        return_log_probs=False,
                        max_steps=len(val_instances[0]['coords']) * config.get('inference', {}).get('max_steps_multiplier', 10),
                        temperature=current_temp,
                        greedy=False,
                        config=config
                    )
                    
                    # Compute validation CPC - SIMPLIFIED
                    val_costs = []
                    for b in range(len(val_instances)):
                        rc = compute_route_cost_gpu(routes_val[b], val_instances[b]["distances"])
                        if not isinstance(rc, torch.Tensor):
                            rc = torch.tensor(rc, device=gpu_manager.device, dtype=torch.float32)
                        val_costs.append(rc)
                    
                    val_costs_tensor = torch.stack(val_costs)
                    n_customers_val = [len(inst['coords']) - 1 for inst in val_instances]
                    batch_val_cost = compute_cpc(val_costs_tensor, n_customers_val, use_geometric_mean, gpu_manager.device).item()
                    
                    val_cost_epoch.append(batch_val_cost)
                
                model.train()
        
        # Epoch statistics
        epoch_time = time.time() - epoch_start
        avg_train_loss = np.mean(train_loss_epoch)
        avg_train_cost = np.mean(train_cost_epoch)
        avg_val_cost = np.mean(val_cost_epoch) if val_cost_epoch else float('nan')
        current_lr = scheduler.get_last_lr()[0] if (scheduler and not isinstance(scheduler, ReduceLROnPlateau)) else optimizer.param_groups[0]['lr']
        
        # Update learning rate scheduler
        if scheduler:
            if isinstance(scheduler, ReduceLROnPlateau):
                scheduler.step(avg_val_cost)
            else:
                scheduler.step()
        
        # Update baseline if needed
        if baseline is not None and epoch > 0:
            baseline.epoch_callback(model, epoch)
        
        # Update history
        history['train_loss'].append(avg_train_loss)
        history['train_cost'].append(avg_train_cost)
        history['val_cost'].append(avg_val_cost)
        history['learning_rate'].append(current_lr)
        history['epoch_time'].append(epoch_time)
        history['temperature'].append(current_temp)
        
        # Memory tracking
        if gpu_manager.device.type == 'cuda':
            allocated = torch.cuda.memory_allocated(gpu_manager.device) / 1024**3
            reserved = torch.cuda.memory_reserved(gpu_manager.device) / 1024**3
            history['gpu_memory'].append({'allocated': allocated, 'reserved': reserved})
        
        # Logging
        if not np.isnan(avg_val_cost):
            logger.info(
                f"[{model.model_type}] Epoch {epoch:03d}: "
                f"train={avg_train_cost:.4f}, val={avg_val_cost:.4f}, "
                f"lr={current_lr:.2e}, temp={current_temp:.3f}, time={epoch_time:.1f}s"
            )
            
            # Track best model
            if avg_val_cost < best_val_cost:
                best_val_cost = avg_val_cost
                if save_dir:
                    best_path = os.path.join(save_dir, 'best_model.pt')
                    torch.save(model.state_dict(), best_path)
        else:
            logger.info(
                f"[{model.model_type}] Epoch {epoch:03d}: "
                f"train={avg_train_cost:.4f}, "
                f"lr={current_lr:.2e}, temp={current_temp:.3f}, time={epoch_time:.1f}s"
            )
        
        # Save checkpoint
        if save_dir and (epoch + 1) % checkpoint_interval == 0:
            checkpoint_path = os.path.join(save_dir, f'checkpoint_epoch_{epoch + 1}.pt')
            torch.save({
                'epoch': epoch,
                'model_state_dict': model.state_dict(),
                'optimizer_state_dict': optimizer.state_dict(),
                'scheduler_state_dict': scheduler.state_dict() if scheduler else None,
                'train_loss': avg_train_loss,
                'val_cost': avg_val_cost,
                'config': config
            }, checkpoint_path)
            logger.info(f"Checkpoint saved to {checkpoint_path}")
        
        # Early stopping check
        if early_stopper and not np.isnan(avg_val_cost):
            if early_stopper(avg_val_cost, model):
                logger.info(f"Early stopping triggered at epoch {epoch}")
                early_stopper.restore_best_weights(model)
                break
    
    # Training complete
    total_time = time.time() - training_start
    
    # Final metrics
    final_metrics = {
        'final_train_cost': history['train_cost'][-1] if history['train_cost'] else None,
        'final_val_cost': history['val_cost'][-1] if history['val_cost'] else None,
        'best_val_cost': best_val_cost,
        'total_time': total_time,
        'avg_epoch_time': total_time / len(history['train_loss']) if history['train_loss'] else 0,
        'peak_gpu_memory': max(m['allocated'] for m in history.get('gpu_memory', [{'allocated': 0}])),
        'device': f"GPU:{gpu_manager.get_device_name()}"
    }
    
    # Add CPC mean type to history
    history['mean_type'] = [mean_type] * len(history['train_cost'])
    
    # Convert history values to proper format
    for key in ['train_cost', 'val_cost']:
        if key in history:
            history[f'{key}_{mean_type}'] = history.pop(key)
    
    logger.info(f"Training completed. Final metrics: {final_metrics}")
    
    return model, {
        'history': dict(history),
        'metrics': final_metrics,
        'config': config
    }
